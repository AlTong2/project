{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import struct\n",
    "from datetime import datetime\n",
    "import pvporcupine\n",
    "from pvrecorder import PvRecorder\n",
    "from pydub import AudioSegment\n",
    "from pydub.playback import play\n",
    "import requests\n",
    "from openai import OpenAI\n",
    "from langchain_community.chat_models import ChatOpenAI\n",
    "import pinecone\n",
    "import os\n",
    "import io\n",
    "import wave\n",
    "import pyaudio\n",
    "import time\n",
    "from google.cloud import speech_v1p1beta1 as speech\n",
    "from gtts import gTTS\n",
    "#from playsound import playsound\n",
    "import pygame\n",
    "\n",
    "import firebase_admin\n",
    "from firebase_admin import credentials, db\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "\n",
    "# type cast\n",
    "actor_id = \"6359e7ea258d1b6dc3abe6e6\"\n",
    "emotion_tone_preset = \"normal-1\"\n",
    "typecast_API_KEY = \"__pltPCLsQuV6MaS4StLkxwkChB2dAeGMwrRvcrY2AvwE\"\n",
    "\n",
    "# pinecone api key\n",
    "api_key = \"e51a52b1-749d-4f5f-9ac8-480f2dd68623\"\n",
    "OPENAI_API_KEY = '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'\n",
    "\n",
    "# user_state (True : 운동중 / False : 휴식중)\n",
    "user_state = False # 운동 시작 버튼 누르기 전에 일단 휴식중 !\n",
    "\n",
    "# pinecone\n",
    "pinecone.init(api_key=api_key, environment='gcp-starter')\n",
    "index_name = \"popo\"\n",
    "index = pinecone.Index(index_name=index_name)\n",
    "\n",
    "# Google Cloud 프로젝트 및 서비스 계정 키\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"/home/altong/Desktop/project/popoteststt-31bc6d0f3189.json\"\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n",
    "api_key = api_key\n",
    "pinecone.init(api_key=api_key, environment='gcp-starter')\n",
    "client = OpenAI()\n",
    "\n",
    "# firebase\n",
    "def current_time():\n",
    "    return datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "\n",
    "# text를 임베딩하는 함수\n",
    "def get_embedding(text):\n",
    "    response = client.embeddings.create(\n",
    "        input=text,\n",
    "        model=\"text-embedding-ada-002\"\n",
    "    )\n",
    "    print(\"Text:\", text)\n",
    "    return response.data[0].embedding\n",
    "\n",
    "# 질문 쿼리\n",
    "def embeding_query(text):\n",
    "    query_result = index.query(\n",
    "        get_embedding(text),\n",
    "        top_k=1,      \n",
    "        include_values=False  \n",
    "    )\n",
    "    print(\"Query Result:\", query_result)\n",
    "    return query_result\n",
    "\n",
    "def is_user_talking(file_path):\n",
    "    # 음성 신호 세기가 일정 값 이상이면 사용자가 말하고 있다고 판단\n",
    "    silence_threshold = 500  # 예시로 설정한 음성 신호 강도 임계값\n",
    "\n",
    "    return get_audio_signal_strength(file_path) > silence_threshold\n",
    "\n",
    "def play_audio(filename):\n",
    "    pygame.mixer.music.load(filename)\n",
    "    pygame.mixer.music.play()\n",
    "    clock = pygame.time.Clock()\n",
    "    while pygame.mixer.music.get_busy():\n",
    "        clock.tick(30)  \n",
    "\n",
    "\n",
    "# typecast\n",
    "def text_to_speech(text, lang='ko', filename='outSound'):\n",
    "    headers = {\n",
    "        'Content-Type': 'application/json',\n",
    "        'Authorization': f'Bearer {typecast_API_KEY}'\n",
    "    }\n",
    "\n",
    "    r = requests.get('https://typecast.ai/api/actor', headers=headers)\n",
    "    my_actors = r.json()['result']\n",
    "    my_first_actor = my_actors[0]\n",
    "    my_first_actor_id = my_first_actor['actor_id']\n",
    "\n",
    "    json_data = {\n",
    "        'text': text,\n",
    "        'lang': lang,\n",
    "        'xapi_hd': True,\n",
    "        'actor_id': my_first_actor_id,\n",
    "        'model_version': 'latest',\n",
    "        'emotion_tone_preset': emotion_tone_preset,\n",
    "        # 'xapi_audio_format' : \"mp3\"\n",
    "\n",
    "    }\n",
    "\n",
    "    response = requests.post('https://typecast.ai/api/speak', headers=headers, json=json_data)\n",
    "\n",
    " \n",
    "    speak_url = response.json()['result']['speak_v2_url']\n",
    "    if response.status_code == 200:\n",
    "        for _ in range(120):\n",
    "        # Download the audio file\n",
    "            audio_response = requests.get(speak_url,headers=headers)\n",
    "            # print(audio_response)\n",
    "            ret = audio_response.json()['result']\n",
    "            print(ret)\n",
    "            if ret['status'] == 'done':\n",
    "                audio_response = requests.get(ret['audio_download_url'])\n",
    "                # print(ra)\n",
    "                with open(filename, 'wb') as f:\n",
    "                    for chunk in audio_response.iter_content(chunk_size=1024):\n",
    "                        if chunk:\n",
    "                            f.write(chunk)\n",
    "                break\n",
    "            else:\n",
    "                # print(f\"status: {ret['status']}, waiting 1 second\")\n",
    "                time.sleep(1)\n",
    "            # f.write(audio_response.content)\n",
    "        # with open(filename, 'wb') as f:\n",
    "        #     f.write(response.content)\n",
    "        # 이전 코드\n",
    "       \n",
    "       \n",
    "        print(\"speaking start\")\n",
    "\n",
    "        pygame.mixer.init()\n",
    "        play_audio(filename)\n",
    "\n",
    "        pygame.mixer.music.stop()\n",
    "        pygame.mixer.quit()\n",
    "        print(\"speaking end\")\n",
    "\n",
    "        os.remove(filename)\n",
    "        print(f\"File '{filename}' deleted successfully.\")\n",
    "    else:\n",
    "        print(f\"Error: Typecast API request failed with status code {response.status_code}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# stt API를 사용하여 음성 파일에서 텍스트를 추출\n",
    "def transcribe_audio(audio_file_path):\n",
    "    client = speech.SpeechClient()\n",
    "\n",
    "    with io.open(audio_file_path, \"rb\") as audio_file:\n",
    "        content = audio_file.read()\n",
    "\n",
    "    audio = speech.RecognitionAudio(content=content)\n",
    "    config = speech.RecognitionConfig(\n",
    "        encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,\n",
    "        sample_rate_hertz=16000,  \n",
    "        language_code=\"ko-KR\",\n",
    "    )\n",
    "    response = client.recognize(config=config, audio=audio)\n",
    "\n",
    "    # 첫 번째 결과만 사용\n",
    "    signal_strength = get_audio_signal_strength(audio_file_path)\n",
    "    if response.results:\n",
    "        transcribed_text = response.results[0].alternatives[0].transcript\n",
    "        return transcribed_text, signal_strength\n",
    "    else:\n",
    "        return \"No speech detected\", signal_strength\n",
    "   \n",
    "# PyAudio를 사용하여 지정된 시간 동안 음성을 녹음하고 WAV 파일로 저장\n",
    "def record_audio(file_path, duration=5):\n",
    "    chunk = 1024\n",
    "    sample_format = pyaudio.paInt16\n",
    "    channels = 1\n",
    "    fs = 16000\n",
    "\n",
    "    p = pyaudio.PyAudio()\n",
    "\n",
    "    stream = p.open(\n",
    "        format=sample_format,\n",
    "        channels=channels,\n",
    "        rate=fs,\n",
    "        frames_per_buffer=chunk,\n",
    "        input=True,\n",
    "    )\n",
    "\n",
    "    frames = []\n",
    "    print(\"Listening...\")\n",
    "\n",
    "    for i in range(0, int(fs / chunk * duration)):\n",
    "        data = stream.read(chunk)\n",
    "        frames.append(data)\n",
    "    print(\"Finished listening.\")\n",
    "\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    p.terminate()\n",
    "\n",
    "    with wave.open(file_path, \"wb\") as wf:\n",
    "        wf.setnchannels(channels)\n",
    "        wf.setsampwidth(pyaudio.PyAudio().get_sample_size(sample_format))\n",
    "        wf.setframerate(fs)\n",
    "        wf.writeframes(b\"\".join(frames))\n",
    "\n",
    "def get_audio_signal_strength(file_path):\n",
    "    from scipy.io import wavfile\n",
    "    samplerate, data = wavfile.read(file_path)\n",
    "    isLoud = False\n",
    "#         import matplotlib.pyplot as plt\n",
    "#         plt.plot([frame for frame in data])\n",
    "#         plt.show()\n",
    "\n",
    "    return max(data)\n",
    "\n",
    "# Initialize Firebase\n",
    "cred = credentials.Certificate(\"altproject-57038-firebase-adminsdk-smksf-df396f61fb.json\")\n",
    "firebase_admin.initialize_app(cred, {'databaseURL': 'https://altproject-57038-default-rtdb.firebaseio.com'})\n",
    "\n",
    "# Firebase Realtime Database reference\n",
    "ref = db.reference('current_routine')\n",
    "\n",
    "while True:\n",
    "        # Read data\n",
    "    current_routine = ref.get()\n",
    "\n",
    "    if current_routine:\n",
    "        user_state = True\n",
    "    else:\n",
    "        user_state = False\n",
    "        if not user_state:\n",
    "\n",
    "\n",
    "            def main():\n",
    "                global user_state\n",
    "                duration = 5\n",
    "                parser = argparse.ArgumentParser()\n",
    "                file_path = \"/home/altong/Desktop/project/wake_word/out_Sound.wav\"\n",
    "\n",
    "                parser.add_argument(\n",
    "                    'access_key',\n",
    "                    help='AccessKey obtained from Picovoice Console (https://console.picovoice.ai/)')\n",
    "\n",
    "                parser.add_argument(\n",
    "                    '--keywords',\n",
    "                    nargs='+',\n",
    "                    help='List of default keywords for detection. Available keywords: %s' % ', '.join(\n",
    "                        '%s' % w for w in sorted(pvporcupine.KEYWORDS)),\n",
    "                    choices=sorted(pvporcupine.KEYWORDS),\n",
    "                    metavar='')\n",
    "\n",
    "                parser.add_argument(\n",
    "                    '--keyword_paths',\n",
    "                    nargs='+',\n",
    "                    help=\"Absolute paths to keyword model files. If not set it will be populated from `--keywords` argument\")\n",
    "\n",
    "                parser.add_argument(\n",
    "                    '--library_path',\n",
    "                    help='Absolute path to dynamic library. Default: using the library provided by `pvporcupine`')\n",
    "\n",
    "                parser.add_argument(\n",
    "                    '--model_path',\n",
    "                    help='Absolute path to the file containing model parameters. '\n",
    "                            'Default: using the library provided by `pvporcupine`')\n",
    "\n",
    "                parser.add_argument(\n",
    "                    '--sensitivities',\n",
    "                    nargs='+',\n",
    "                    help=\"Sensitivities for detecting keywords. Each value should be a number within [0, 1]. A higher \"\n",
    "                            \"sensitivity results in fewer misses at the cost of increasing the false alarm rate. If not set 0.5 \"\n",
    "                            \"will be used.\",\n",
    "                    type=float,\n",
    "                    default=None)\n",
    "\n",
    "                parser.add_argument('--audio_device_index', help='Index of input audio device.', type=int, default=-1)\n",
    "\n",
    "                parser.add_argument('--output_path', help='Absolute path to recorded audio for debugging.', default=None)\n",
    "\n",
    "                parser.add_argument('--show_audio_devices', action='store_true')\n",
    "\n",
    "                # 주피터 노트북에서 실행할 때 필요한 부분\n",
    "                args = parser.parse_args(['p90iMxGEpK2tPVgoF1nGJKP0moq36DjgbPwWeCGlArHGBFabl/qgFw==',\n",
    "                                            '--keyword_paths', '/home/altong/Desktop/project/wake_word/altong_ko_jetson_v3_0_0.ppn',\n",
    "                                            '--model_path', '/home/altong/Desktop/project/wake_word/porcupine_params_ko.pv'])\n",
    "\n",
    "                if args.show_audio_devices:\n",
    "                    for i, device in enumerate(PvRecorder.get_available_devices()):\n",
    "                        print('Device %d: %s' % (i, device))\n",
    "                        return\n",
    "\n",
    "                if args.keyword_paths is None:\n",
    "                    if args.keywords is None:\n",
    "                        raise ValueError(\"Either `--keywords` or `--keyword_paths` must be set.\")\n",
    "\n",
    "                    keyword_paths = [pvporcupine.KEYWORD_PATHS[x] for x in args.keywords]\n",
    "                else:\n",
    "                    keyword_paths = args.keyword_paths\n",
    "\n",
    "                if args.sensitivities is None:\n",
    "                    args.sensitivities = [0.5] * len(keyword_paths)\n",
    "\n",
    "                if len(keyword_paths) != len(args.sensitivities):\n",
    "                    raise ValueError('Number of keywords does not match the number of sensitivities.')\n",
    "\n",
    "                try:\n",
    "                    porcupine = pvporcupine.create(\n",
    "                        access_key=args.access_key,\n",
    "                        library_path=args.library_path,\n",
    "                        model_path=args.model_path,\n",
    "                        keyword_paths=keyword_paths,\n",
    "                        sensitivities=args.sensitivities)\n",
    "                except pvporcupine.PorcupineInvalidArgumentError as e:\n",
    "                    print(\"One or more arguments provided to Porcupine is invalid: \", args)\n",
    "                    print(e)\n",
    "                    raise e\n",
    "                except pvporcupine.PorcupineActivationError as e:\n",
    "                    print(\"AccessKey activation error\")\n",
    "                    raise e\n",
    "                except pvporcupine.PorcupineActivationLimitError as e:\n",
    "                    print(\"AccessKey '%s' has reached it's temporary device limit\" % args.access_key)\n",
    "                    raise e\n",
    "                except pvporcupine.PorcupineActivationRefusedError as e:\n",
    "                    print(\"AccessKey '%s' refused\" % args.access_key)\n",
    "                    raise e\n",
    "                except pvporcupine.PorcupineActivationThrottledError as e:\n",
    "                    print(\"AccessKey '%s' has been throttled\" % args.access_key)\n",
    "                    raise e\n",
    "                except pvporcupine.PorcupineError as e:\n",
    "                    print(\"Failed to initialize Porcupine\")\n",
    "                    raise e\n",
    "\n",
    "                keywords = list()\n",
    "                for x in keyword_paths:\n",
    "                    keyword_phrase_part = os.path.basename(x).replace('.ppn', '').split('_')\n",
    "                    if len(keyword_phrase_part) > 6:\n",
    "                        keywords.append(' '.join(keyword_phrase_part[0:-6]))\n",
    "                    else:\n",
    "                        keywords.append(keyword_phrase_part[0])\n",
    "\n",
    "                # print('Porcupine version: %s' % porcupine.version)\n",
    "\n",
    "                recorder = PvRecorder(\n",
    "                    frame_length=porcupine.frame_length,\n",
    "                    device_index=args.audio_device_index)\n",
    "                recorder.start()\n",
    "\n",
    "                wav_file = None\n",
    "                if args.output_path is not None:\n",
    "                    wav_file = wave.open(args.output_path, \"w\")\n",
    "                    wav_file.setnchannels(1)\n",
    "                    wav_file.setsampwidth(2)\n",
    "                    wav_file.setframerate(16000)\n",
    "\n",
    "                print('Listening !!! ')\n",
    "\n",
    "                try:\n",
    "                    if not user_state :\n",
    "                        while True:\n",
    "                            if not user_state:\n",
    "                                pcm = recorder.read()\n",
    "                                result = porcupine.process(pcm)\n",
    "\n",
    "                                if wav_file is not None:\n",
    "                                    wav_file.writeframes(struct.pack(\"h\" * len(pcm), *pcm))\n",
    "\n",
    "                                if result >= 0:\n",
    "                                    detected_keyword = keywords[result]\n",
    "                                    text_to_speech(\"알통이 등장\", lang='ko', filename='outSound.wav')\n",
    "                            elif user_state:\n",
    "                                break\n",
    "\n",
    "                            # play_audio('outSound.wav')\n",
    "                            if not user_state :\n",
    "                                while True:\n",
    "                                    print('[%s] Detected %s' % (str(datetime.now()), detected_keyword))\n",
    "\n",
    "                                            # 음성 녹음\n",
    "                                    record_audio(file_path, duration)\n",
    "\n",
    "                                            # 음성을 텍스트로 변환\n",
    "                                    transcribed_text = transcribe_audio(file_path)\n",
    "\n",
    "                                            # 변환된 텍스트를 출력\n",
    "                                    print(\"Transcribed Text:\", transcribed_text)\n",
    "\n",
    "                                            # embeding_query 함수를 호출하여 query_result를 얻어오기\n",
    "                                    query_result = embeding_query(transcribed_text[0])\n",
    "\n",
    "                                            # 정확도 (score)가 0.85 이상인 경우\n",
    "                                    if query_result['matches'][0]['score'] >= 0.85:\n",
    "                                                # 해당 id에 따라 다른 동작 수행\n",
    "                                        if query_result['matches'][0]['id'] == 'record':\n",
    "                                            text_to_speech(\"오늘 운동한 시간은 총 30분 입니다!\", lang='ko', filename='outSound.wav')\n",
    "                                            user_state = True\n",
    "                                            break\n",
    "                                        elif query_result['matches'][0]['id'] == 'calorie':\n",
    "                                            text_to_speech(\"오늘 소비한 칼로리는 총 100칼로리 입니다!\", lang='ko', filename='outSound.wav')\n",
    "                                            user_state = True\n",
    "                                            break\n",
    "\n",
    "\n",
    "                                    elif query_result['matches'][0]['score'] < 0.85 and not transcribed_text[0] == 'No speech detected':\n",
    "                                        # openai 답변 받아오기\n",
    "                                        chat_model = ChatOpenAI(openai_api_key=OPENAI_API_KEY)\n",
    "                                        response_stream = chat_model.predict(transcribed_text[0], stream=True)\n",
    "                                        text_to_speech(response_stream, lang='ko', filename='outSound.wav')\n",
    "                                        user_state = True\n",
    "                                        break\n",
    "\n",
    "   \n",
    "\n",
    "\n",
    "                except KeyboardInterrupt:\n",
    "                    print('Stopping !!!')\n",
    "                finally:\n",
    "                    recorder.delete()\n",
    "                    porcupine.delete()\n",
    "                    ref.delete()\n",
    "                    if wav_file is not None:\n",
    "                        wav_file.close()\n",
    "\n",
    "            if __name__ == '__main__':\n",
    "                pygame.init()\n",
    "                pygame.mixer.init()\n",
    "                main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
