{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cee7f238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pvporcupine\n",
      "  Obtaining dependency information for pvporcupine from https://files.pythonhosted.org/packages/7e/97/37429fa6bfa07ed960d8852b08dc2be95b852d4304fec6884eb47f20386c/pvporcupine-3.0.1-py3-none-any.whl.metadata\n",
      "  Using cached pvporcupine-3.0.1-py3-none-any.whl.metadata (4.9 kB)\n",
      "Using cached pvporcupine-3.0.1-py3-none-any.whl (2.7 MB)\n",
      "Installing collected packages: pvporcupine\n",
      "Successfully installed pvporcupine-3.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install pvporcupine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d71d40a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pvrecorder\n",
      "  Obtaining dependency information for pvrecorder from https://files.pythonhosted.org/packages/57/bb/7ff26758d3e7332982aba98efa3da50a98903921a3df744bf456eaa29376/pvrecorder-1.2.1-py3-none-any.whl.metadata\n",
      "  Using cached pvrecorder-1.2.1-py3-none-any.whl.metadata (2.0 kB)\n",
      "Using cached pvrecorder-1.2.1-py3-none-any.whl (4.0 MB)\n",
      "Installing collected packages: pvrecorder\n",
      "Successfully installed pvrecorder-1.2.1\n"
     ]
    }
   ],
   "source": [
    "!pip install pvrecorder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c6696f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pydub\n",
      "  Using cached pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Installing collected packages: pydub\n",
      "Successfully installed pydub-0.25.1\n"
     ]
    }
   ],
   "source": [
    "!pip install pydub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c77687b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gtts\n",
      "  Obtaining dependency information for gtts from https://files.pythonhosted.org/packages/6a/4f/b133719e7638ca68f8805dd75731371db8d5ed23be84d6fc30845a46bedb/gTTS-2.5.0-py3-none-any.whl.metadata\n",
      "  Using cached gTTS-2.5.0-py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: requests<3,>=2.27 in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from gtts) (2.31.0)\n",
      "Requirement already satisfied: click<8.2,>=7.1 in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from gtts) (8.0.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from click<8.2,>=7.1->gtts) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from requests<3,>=2.27->gtts) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from requests<3,>=2.27->gtts) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from requests<3,>=2.27->gtts) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from requests<3,>=2.27->gtts) (2023.11.17)\n",
      "Using cached gTTS-2.5.0-py3-none-any.whl (29 kB)\n",
      "Installing collected packages: gtts\n",
      "Successfully installed gtts-2.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install gtts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2a21a69",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "운동 종류를 입력하세요 ('squat', 'pushup', 'pullup'): pushup\n",
      "운동 횟수 :3\n",
      "휴식 시간 :5\n",
      "세트 수 :3\n",
      "\n",
      "1세트를 시작합니다.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SMHRD\\anaconda3\\Lib\\site-packages\\google\\protobuf\\symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "운동 횟수: 1회\n",
      "speaking start\n",
      "speaking end\n",
      "File 'outSound.mp3' deleted successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SMHRD\\anaconda3\\Lib\\site-packages\\google\\protobuf\\symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "운동 횟수: 2회\n",
      "speaking start\n",
      "speaking end\n",
      "File 'outSound.mp3' deleted successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SMHRD\\anaconda3\\Lib\\site-packages\\google\\protobuf\\symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "운동 횟수: 3회\n",
      "speaking start\n",
      "speaking end\n",
      "File 'outSound.mp3' deleted successfully.\n",
      "운동 횟수 3 달성 또는 시간 초과! 동영상 녹화를 중지합니다.\n",
      "\n",
      "휴식 시간 5초를 기다립니다...\n",
      "\n",
      "Listening !!! \n",
      "\n",
      "2세트를 시작합니다.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SMHRD\\anaconda3\\Lib\\site-packages\\google\\protobuf\\symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "운동 횟수: 1회\n",
      "speaking start\n",
      "speaking end\n",
      "File 'outSound.mp3' deleted successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SMHRD\\anaconda3\\Lib\\site-packages\\google\\protobuf\\symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "운동 횟수: 2회\n",
      "speaking start\n",
      "speaking end\n",
      "File 'outSound.mp3' deleted successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SMHRD\\anaconda3\\Lib\\site-packages\\google\\protobuf\\symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "운동 횟수: 3회\n",
      "speaking start\n",
      "speaking end\n",
      "File 'outSound.mp3' deleted successfully.\n",
      "운동 횟수 3 달성 또는 시간 초과! 동영상 녹화를 중지합니다.\n",
      "\n",
      "휴식 시간 5초를 기다립니다...\n",
      "\n",
      "Listening !!! \n",
      "\n",
      "3세트를 시작합니다.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SMHRD\\anaconda3\\Lib\\site-packages\\google\\protobuf\\symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "운동 횟수: 1회\n",
      "speaking start\n",
      "speaking end\n",
      "File 'outSound.mp3' deleted successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SMHRD\\anaconda3\\Lib\\site-packages\\google\\protobuf\\symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "운동 횟수: 2회\n",
      "speaking start\n",
      "speaking end\n",
      "File 'outSound.mp3' deleted successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SMHRD\\anaconda3\\Lib\\site-packages\\google\\protobuf\\symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "운동 횟수: 3회\n",
      "speaking start\n",
      "speaking end\n",
      "File 'outSound.mp3' deleted successfully.\n",
      "운동 횟수 3 달성 또는 시간 초과! 동영상 녹화를 중지합니다.\n",
      "Listening !!! \n",
      "Stopping !!!\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 760\u001b[0m\n\u001b[0;32m    758\u001b[0m pygame\u001b[38;5;241m.\u001b[39minit()\n\u001b[0;32m    759\u001b[0m pygame\u001b[38;5;241m.\u001b[39mmixer\u001b[38;5;241m.\u001b[39minit()\n\u001b[1;32m--> 760\u001b[0m main()\n",
      "Cell \u001b[1;32mIn[6], line 311\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    308\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNumber of keywords does not match the number of sensitivities.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    310\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 311\u001b[0m     porcupine \u001b[38;5;241m=\u001b[39m pvporcupine\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[0;32m    312\u001b[0m         access_key\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39maccess_key,\n\u001b[0;32m    313\u001b[0m         library_path\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mlibrary_path,\n\u001b[0;32m    314\u001b[0m         model_path\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mmodel_path,\n\u001b[0;32m    315\u001b[0m         keyword_paths\u001b[38;5;241m=\u001b[39mkeyword_paths,\n\u001b[0;32m    316\u001b[0m         sensitivities\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39msensitivities)\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m pvporcupine\u001b[38;5;241m.\u001b[39mPorcupineInvalidArgumentError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOne or more arguments provided to Porcupine is invalid: \u001b[39m\u001b[38;5;124m\"\u001b[39m, args)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pvporcupine\\_factory.py:69\u001b[0m, in \u001b[0;36mcreate\u001b[1;34m(access_key, library_path, model_path, keyword_paths, keywords, sensitivities)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(sensitivities) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(keyword_paths):\n\u001b[0;32m     67\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of keywords does not match the number of sensitivities.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 69\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Porcupine(\n\u001b[0;32m     70\u001b[0m     access_key\u001b[38;5;241m=\u001b[39maccess_key,\n\u001b[0;32m     71\u001b[0m     library_path\u001b[38;5;241m=\u001b[39mlibrary_path,\n\u001b[0;32m     72\u001b[0m     model_path\u001b[38;5;241m=\u001b[39mmodel_path,\n\u001b[0;32m     73\u001b[0m     keyword_paths\u001b[38;5;241m=\u001b[39mkeyword_paths,\n\u001b[0;32m     74\u001b[0m     sensitivities\u001b[38;5;241m=\u001b[39msensitivities)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pvporcupine\\_porcupine.py:190\u001b[0m, in \u001b[0;36mPorcupine.__init__\u001b[1;34m(self, access_key, library_path, model_path, keyword_paths, sensitivities)\u001b[0m\n\u001b[0;32m    186\u001b[0m init_func\u001b[38;5;241m.\u001b[39mrestype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mPicovoiceStatuses\n\u001b[0;32m    188\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle \u001b[38;5;241m=\u001b[39m POINTER(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mCPorcupine)()\n\u001b[1;32m--> 190\u001b[0m status \u001b[38;5;241m=\u001b[39m init_func(\n\u001b[0;32m    191\u001b[0m     access_key\u001b[38;5;241m.\u001b[39mencode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[0;32m    192\u001b[0m     model_path\u001b[38;5;241m.\u001b[39mencode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[0;32m    193\u001b[0m     \u001b[38;5;28mlen\u001b[39m(keyword_paths),\n\u001b[0;32m    194\u001b[0m     (c_char_p \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(keyword_paths))(\u001b[38;5;241m*\u001b[39m[os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexpanduser(x)\u001b[38;5;241m.\u001b[39mencode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m keyword_paths]),\n\u001b[0;32m    195\u001b[0m     (c_float \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(keyword_paths))(\u001b[38;5;241m*\u001b[39msensitivities),\n\u001b[0;32m    196\u001b[0m     byref(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle))\n\u001b[0;32m    197\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mPicovoiceStatuses\u001b[38;5;241m.\u001b[39mSUCCESS:\n\u001b[0;32m    198\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_PICOVOICE_STATUS_TO_EXCEPTION[status](\n\u001b[0;32m    199\u001b[0m         message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInitialization failed\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    200\u001b[0m         message_stack\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_error_stack())\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\enum.py:686\u001b[0m, in \u001b[0;36mEnumType.__call__\u001b[1;34m(cls, value, names, module, qualname, type, start, boundary)\u001b[0m\n\u001b[0;32m    681\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    682\u001b[0m \u001b[38;5;124;03m    classes/types should always be True.\u001b[39;00m\n\u001b[0;32m    683\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m    684\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 686\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mcls\u001b[39m, value, names\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m, module\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, qualname\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, start\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, boundary\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    687\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    688\u001b[0m \u001b[38;5;124;03m    Either returns an existing member, or creates a new enum class.\u001b[39;00m\n\u001b[0;32m    689\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    709\u001b[0m \u001b[38;5;124;03m    `type`, if set, will be mixed in as the first base class.\u001b[39;00m\n\u001b[0;32m    710\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m    711\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m names \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# simple value lookup\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#*********************************** openai import ************************************\n",
    "import argparse\n",
    "import struct\n",
    "from datetime import datetime\n",
    "import pvporcupine\n",
    "from pvrecorder import PvRecorder\n",
    "from pydub import AudioSegment\n",
    "from pydub.playback import play\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from openai import OpenAI\n",
    "import pinecone\n",
    "import os\n",
    "import io\n",
    "import wave\n",
    "import pyaudio\n",
    "import time\n",
    "from google.cloud import speech_v1p1beta1 as speech\n",
    "from gtts import gTTS\n",
    "from playsound import playsound\n",
    "import pygame\n",
    "\n",
    "# ******************************************* mediapipe import *****************************************\n",
    "import numpy as np\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ******************************************* 함수 정의 ******************************************\n",
    "# text를 임베딩하는 함수\n",
    "def get_embedding(text):\n",
    "    response = client.embeddings.create(\n",
    "        input=text,\n",
    "        model=\"text-embedding-ada-002\"\n",
    "    )\n",
    "    print(\"Text:\", text)\n",
    "    return response.data[0].embedding\n",
    "\n",
    "# 질문 쿼리\n",
    "def embeding_query(text):\n",
    "    query_result = index.query(\n",
    "        get_embedding(text), \n",
    "        top_k=1,      \n",
    "        include_values=False  \n",
    "    )\n",
    "    print(\"Query Result:\", query_result)\n",
    "    return query_result\n",
    "\n",
    "def is_user_talking(file_path):\n",
    "    # 음성 신호 세기가 일정 값 이상이면 사용자가 말하고 있다고 판단\n",
    "    silence_threshold = 1500  # 예시로 설정한 음성 신호 강도 임계값\n",
    "\n",
    "    return get_audio_signal_strength(file_path) > silence_threshold\n",
    "\n",
    "def play_audio(filename):\n",
    "    # if os.path.exists(filename):\n",
    "    #     sound = AudioSegment.from_file(filename)\n",
    "    #     play(sound)\n",
    "    # else:\n",
    "    #     print(f\"Error: File '{filename}' not found.\")   \n",
    "    \n",
    "    pygame.mixer.music.load(filename)\n",
    "    pygame.mixer.music.play()\n",
    "    # pygame.mixer.music.set_endevent(pygame.USEREVENT)\n",
    "    clock = pygame.time.Clock()\n",
    "    while pygame.mixer.music.get_busy():\n",
    "        clock.tick(30)  \n",
    "\n",
    "# gTTS 라이브러리를 사용하여 텍스트를 지정된 언어로 음성으로 변환하고 MP3 파일로 저장, 재생        \n",
    "def text_to_speech(text, lang='ko', filename='outSound.mp3'):\n",
    "    tts = gTTS(text=text, lang=lang)\n",
    "    tts.save(filename)\n",
    "    print(\"speaking start\")\n",
    "    \n",
    "    if os.path.exists(filename):\n",
    "        pygame.mixer.init()\n",
    "        play_audio(filename)\n",
    "         # 이벤트를 활용하여 재생 종료를 기다림\n",
    "        pygame.event.wait()\n",
    "\n",
    "        # Pygame의 오디오 재생이 완전히 종료될 때까지 대기\n",
    "        pygame.mixer.music.stop()\n",
    "        pygame.mixer.quit()\n",
    "        print(\"speaking end\")\n",
    "        os.remove(filename)\n",
    "        print(f\"File '{filename}' deleted successfully.\")\n",
    "    else:\n",
    "        print(f\"Error: File '{filename}' not found.\")\n",
    "\n",
    "\n",
    "\n",
    "# stt API를 사용하여 음성 파일에서 텍스트를 추출\n",
    "def transcribe_audio(audio_file_path):\n",
    "    client = speech.SpeechClient()\n",
    "\n",
    "    with io.open(audio_file_path, \"rb\") as audio_file:\n",
    "        content = audio_file.read()\n",
    "\n",
    "    audio = speech.RecognitionAudio(content=content)\n",
    "    config = speech.RecognitionConfig(\n",
    "        encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,\n",
    "        sample_rate_hertz=16000,  \n",
    "        language_code=\"ko-KR\",\n",
    "    )\n",
    "    response = client.recognize(config=config, audio=audio)\n",
    "\n",
    "    # 첫 번째 결과만 사용\n",
    "    signal_strength = get_audio_signal_strength(audio_file_path)\n",
    "    if response.results:\n",
    "        transcribed_text = response.results[0].alternatives[0].transcript\n",
    "        return transcribed_text, signal_strength\n",
    "    else:\n",
    "        return \"No speech detected\", signal_strength\n",
    "    \n",
    "# PyAudio를 사용하여 지정된 시간 동안 음성을 녹음하고 WAV 파일로 저장\n",
    "def record_audio(file_path, duration=5):\n",
    "    chunk = 1024\n",
    "    sample_format = pyaudio.paInt16\n",
    "    channels = 1\n",
    "    fs = 16000\n",
    "\n",
    "    p = pyaudio.PyAudio()\n",
    "\n",
    "    stream = p.open(\n",
    "        format=sample_format,\n",
    "        channels=channels,\n",
    "        rate=fs,\n",
    "        frames_per_buffer=chunk,\n",
    "        input=True,\n",
    "    )\n",
    "\n",
    "    frames = []\n",
    "    print(\"Listening...\")\n",
    "\n",
    "    for i in range(0, int(fs / chunk * duration)):\n",
    "        data = stream.read(chunk)\n",
    "        frames.append(data)\n",
    "    print(\"Finished listening.\")\n",
    "\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    p.terminate()\n",
    "\n",
    "    with wave.open(file_path, \"wb\") as wf:\n",
    "        wf.setnchannels(channels)\n",
    "        wf.setsampwidth(pyaudio.PyAudio().get_sample_size(sample_format))\n",
    "        wf.setframerate(fs)\n",
    "        wf.writeframes(b\"\".join(frames))\n",
    "\n",
    "def get_audio_signal_strength(file_path):\n",
    "    from scipy.io import wavfile\n",
    "    samplerate, data = wavfile.read(file_path)\n",
    "    isLoud = False\n",
    "#         import matplotlib.pyplot as plt\n",
    "#         plt.plot([frame for frame in data])\n",
    "#         plt.show()\n",
    "\n",
    "    return max(data)\n",
    "\n",
    "# 각 앵글을 계산하는 함수\n",
    "def calculate_angle(a, b, c):\n",
    "    radians = math.atan2(c[1] - b[1], c[0] - b[0]) - math.atan2(a[1] - b[1], a[0] - b[0])\n",
    "    angle = math.degrees(radians)\n",
    "    return angle + 360 if angle < 0 else angle\n",
    "\n",
    "\n",
    "# ****************************************** openai 변수 정의 ***************************************\n",
    "\n",
    "# pinecone api key\n",
    "api_key = \"e51a52b1-749d-4f5f-9ac8-480f2dd68623\"\n",
    "OPENAI_API_KEY = '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'\n",
    "\n",
    "# user_state (True : 운동중 / False : 휴식중)\n",
    "user_state = False # 운동 시작 버튼 누르기 전에 일단 휴식중 !\n",
    "\n",
    "# pinecone\n",
    "pinecone.init(api_key=api_key, environment='gcp-starter')\n",
    "index_name = \"popo\"\n",
    "index = pinecone.Index(index_name=index_name)\n",
    "\n",
    "# Google Cloud 프로젝트 및 서비스 계정 키\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"C:/Users/SMHRD/Downloads/popoteststt-31bc6d0f3189.json\"\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n",
    "api_key = api_key\n",
    "pinecone.init(api_key=api_key, environment='gcp-starter')\n",
    "client = OpenAI()\n",
    "\n",
    "# 사용자에게 입력받기\n",
    "exercise_type = input(\"운동 종류를 입력하세요 ('squat', 'pushup', 'pullup'): \")\n",
    "input_count = int(input('운동 횟수 :'))\n",
    "input_rest = input('휴식 시간 :')\n",
    "input_sets = input('세트 수 :')\n",
    "\n",
    "if exercise_type :\n",
    "    user_state = True\n",
    "\n",
    "#******************************************** mediapipe 변수 정의 *************************************\n",
    "def main():\n",
    "    while True :\n",
    "        global user_state\n",
    "        # 미디어파이프 모듈 초기화\n",
    "        mp_pose = mp.solutions.pose\n",
    "        pose = mp_pose.Pose()\n",
    "        mp_drawing = mp.solutions.drawing_utils \n",
    "\n",
    "        # 화면에 text font 설정\n",
    "        font = cv2.FONT_HERSHEY_DUPLEX\n",
    "        count_position = (20, 30)\n",
    "\n",
    "        # 각 관절의 인덱스\n",
    "        JOINTS = {\n",
    "            \"right_shoulder\": 12,\n",
    "            \"right_elbow\": 14,\n",
    "            \"right_wrist\": 16,\n",
    "            \"left_shoulder\": 11,\n",
    "            \"left_elbow\": 13,\n",
    "            \"left_wrist\": 15,\n",
    "            \"right_hip\": 24,\n",
    "            \"right_knee\": 26,\n",
    "            \"right_ankle\": 28,\n",
    "            \"left_hip\": 23,\n",
    "            \"left_knee\": 25,\n",
    "            \"left_ankle\": 27,\n",
    "        }\n",
    "\n",
    "        # 카메라 설정\n",
    "        cap = cv2.VideoCapture('푸쉬업.mp4')\n",
    "\n",
    "        # 데이터 기록을 위한 리스트\n",
    "        right_shoulder_elbow_wrist_angles = []\n",
    "        left_shoulder_elbow_wrist_angles = []\n",
    "        right_hip_knee_ankle_angles = []\n",
    "        left_hip_knee_ankle_angles = []\n",
    "        right_knee_hip_shoulder_angles = []\n",
    "        left_knee_hip_shoulder_angles = []\n",
    "        right_ankle_hip_shoulder_angles = []\n",
    "        left_ankle_hip_shoulder_angles = []\n",
    "\n",
    "\n",
    "        duration = 5\n",
    "        parser = argparse.ArgumentParser()\n",
    "        file_path = \"C://Users//SMHRD//Desktop//wake_word//outSound.wav\"\n",
    "\n",
    "        parser.add_argument(\n",
    "            'access_key',\n",
    "            help='AccessKey obtained from Picovoice Console (https://console.picovoice.ai/)')\n",
    "\n",
    "        parser.add_argument(\n",
    "            '--keywords',\n",
    "            nargs='+',\n",
    "            help='List of default keywords for detection. Available keywords: %s' % ', '.join(\n",
    "                '%s' % w for w in sorted(pvporcupine.KEYWORDS)),\n",
    "            choices=sorted(pvporcupine.KEYWORDS),\n",
    "            metavar='')\n",
    "\n",
    "        parser.add_argument(\n",
    "            '--keyword_paths',\n",
    "            nargs='+',\n",
    "            help=\"Absolute paths to keyword model files. If not set it will be populated from `--keywords` argument\")\n",
    "\n",
    "        parser.add_argument(\n",
    "            '--library_path',\n",
    "            help='Absolute path to dynamic library. Default: using the library provided by `pvporcupine`')\n",
    "\n",
    "        parser.add_argument(\n",
    "            '--model_path',\n",
    "            help='Absolute path to the file containing model parameters. '\n",
    "                    'Default: using the library provided by `pvporcupine`')\n",
    "\n",
    "        parser.add_argument(\n",
    "            '--sensitivities',\n",
    "            nargs='+',\n",
    "            help=\"Sensitivities for detecting keywords. Each value should be a number within [0, 1]. A higher \"\n",
    "                    \"sensitivity results in fewer misses at the cost of increasing the false alarm rate. If not set 0.5 \"\n",
    "                    \"will be used.\",\n",
    "            type=float,\n",
    "            default=None)\n",
    "\n",
    "        parser.add_argument('--audio_device_index', help='Index of input audio device.', type=int, default=-1)\n",
    "\n",
    "        parser.add_argument('--output_path', help='Absolute path to recorded audio for debugging.', default=None)\n",
    "\n",
    "        parser.add_argument('--show_audio_devices', action='store_true')\n",
    "\n",
    "        # 주피터 노트북에서 실행할 때 필요한 부분\n",
    "        args = parser.parse_args(['hlnQjpe3dS7hDYzdO7M1oQroP2RsEFMzm4q1bQOt39G8Q2GWpUzzJA==',\n",
    "                                    '--keyword_paths', 'C:\\\\Users\\\\SMHRD\\\\Desktop\\\\wake_word\\\\altong_ko_windows_v3_0_0.ppn',\n",
    "                                    '--model_path', 'C:\\\\Users\\\\SMHRD\\\\Desktop\\\\wake_word\\\\porcupine_params_ko.pv'])\n",
    "\n",
    "        if args.show_audio_devices:\n",
    "            for i, device in enumerate(PvRecorder.get_available_devices()):\n",
    "                print('Device %d: %s' % (i, device))\n",
    "            return\n",
    "\n",
    "        if args.keyword_paths is None:\n",
    "            if args.keywords is None:\n",
    "                raise ValueError(\"Either `--keywords` or `--keyword_paths` must be set.\")\n",
    "\n",
    "            keyword_paths = [pvporcupine.KEYWORD_PATHS[x] for x in args.keywords]\n",
    "        else:\n",
    "            keyword_paths = args.keyword_paths\n",
    "\n",
    "        if args.sensitivities is None:\n",
    "            args.sensitivities = [0.5] * len(keyword_paths)\n",
    "\n",
    "        if len(keyword_paths) != len(args.sensitivities):\n",
    "            raise ValueError('Number of keywords does not match the number of sensitivities.')\n",
    "\n",
    "        try:\n",
    "            porcupine = pvporcupine.create(\n",
    "                access_key=args.access_key,\n",
    "                library_path=args.library_path,\n",
    "                model_path=args.model_path,\n",
    "                keyword_paths=keyword_paths,\n",
    "                sensitivities=args.sensitivities)\n",
    "        except pvporcupine.PorcupineInvalidArgumentError as e:\n",
    "            print(\"One or more arguments provided to Porcupine is invalid: \", args)\n",
    "            print(e)\n",
    "            raise e\n",
    "        except pvporcupine.PorcupineActivationError as e:\n",
    "            print(\"AccessKey activation error\")\n",
    "            raise e\n",
    "        except pvporcupine.PorcupineActivationLimitError as e:\n",
    "            print(\"AccessKey '%s' has reached it's temporary device limit\" % args.access_key)\n",
    "            raise e\n",
    "        except pvporcupine.PorcupineActivationRefusedError as e:\n",
    "            print(\"AccessKey '%s' refused\" % args.access_key)\n",
    "            raise e\n",
    "        except pvporcupine.PorcupineActivationThrottledError as e:\n",
    "            print(\"AccessKey '%s' has been throttled\" % args.access_key)\n",
    "            raise e\n",
    "        except pvporcupine.PorcupineError as e:\n",
    "            print(\"Failed to initialize Porcupine\")\n",
    "            raise e\n",
    "\n",
    "        keywords = list()\n",
    "        for x in keyword_paths:\n",
    "            keyword_phrase_part = os.path.basename(x).replace('.ppn', '').split('_')\n",
    "            if len(keyword_phrase_part) > 6:\n",
    "                keywords.append(' '.join(keyword_phrase_part[0:-6]))\n",
    "            else:\n",
    "                keywords.append(keyword_phrase_part[0])\n",
    "\n",
    "            # print('Porcupine version: %s' % porcupine.version)\n",
    "\n",
    "        recorder = PvRecorder(\n",
    "            frame_length=porcupine.frame_length,\n",
    "            device_index=args.audio_device_index)\n",
    "        recorder.start()\n",
    "\n",
    "        wav_file = None\n",
    "        if args.output_path is not None:\n",
    "            wav_file = wave.open(args.output_path, \"w\")\n",
    "            wav_file.setnchannels(1)\n",
    "            wav_file.setsampwidth(2)\n",
    "            wav_file.setframerate(16000)\n",
    "\n",
    " \n",
    "        if user_state == False :\n",
    "            print('Listening !!! ')\n",
    "            try:\n",
    "                while True:\n",
    "                    pcm = recorder.read()\n",
    "                    result = porcupine.process(pcm)\n",
    "\n",
    "\n",
    "                    if wav_file is not None:\n",
    "                        wav_file.writeframes(struct.pack(\"h\" * len(pcm), *pcm))\n",
    "\n",
    "                    if result >= 0:\n",
    "                        detected_keyword = keywords[result]\n",
    "                        text_to_speech(\"알통이 등장\", lang='ko', filename='outSound.mp3')\n",
    "                        # play_audio('outSound.mp3')\n",
    "\n",
    "\n",
    "                        while True:\n",
    "                            print('[%s] Detected %s' % (str(datetime.now()), detected_keyword))\n",
    "\n",
    "                            # 음성 녹음\n",
    "                            record_audio(file_path, duration)\n",
    "\n",
    "                            # 음성을 텍스트로 변환\n",
    "                            transcribed_text = transcribe_audio(file_path)\n",
    "\n",
    "                            # 변환된 텍스트를 출력\n",
    "                            print(\"Transcribed Text:\", transcribed_text)\n",
    "\n",
    "                            # embeding_query 함수를 호출하여 query_result를 얻어오기\n",
    "                            query_result = embeding_query(transcribed_text[0])\n",
    "\n",
    "                            # 정확도 (score)가 0.85 이상인 경우\n",
    "                            if query_result['matches'][0]['score'] >= 0.85:\n",
    "                                # 해당 id에 따라 다른 동작 수행\n",
    "                                if query_result['matches'][0]['id'] == 'record':\n",
    "                                    text_to_speech(\"오늘 운동한 시간은 총 30분 입니다!\", lang='ko', filename='outSound.mp3')\n",
    "                                    # break\n",
    "                                elif query_result['matches'][0]['id'] == 'calorie':\n",
    "                                    text_to_speech(\"오늘 소비한 칼로리는 총 100칼로리 입니다!\", lang='ko', filename='outSound.mp3')\n",
    "                                    # break\n",
    "                                elif not is_user_talking(file_path):\n",
    "                                    text_to_speech(\"아무 말도 없으셔서 종료합니다.\", lang='ko', filename='outSound.mp3')\n",
    "                                    break\n",
    "\n",
    "                            elif query_result['matches'][0]['score'] < 0.85 and not transcribed_text[0] == 'No speech detected':\n",
    "                                # openai 답변 받아오기\n",
    "                                chat_model = ChatOpenAI(openai_api_key=OPENAI_API_KEY)\n",
    "                                response_stream = chat_model.predict(transcribed_text[0], stream=True)\n",
    "                                text_to_speech(response_stream, lang='ko', filename='outSound.mp3')\n",
    "                                break\n",
    "\n",
    "                                if not is_user_talking(file_path):\n",
    "                                    text_to_speech(\"아무 말도 없으셔서 종료합니다.\", lang='ko', filename='outSound.mp3')\n",
    "                                    break\n",
    "\n",
    "\n",
    "\n",
    "            except KeyboardInterrupt:\n",
    "                print('Stopping !!!')\n",
    "            finally:\n",
    "                recorder.delete()\n",
    "                porcupine.delete()\n",
    "                if wav_file is not None:\n",
    "                    wav_file.close()\n",
    "\n",
    "        elif user_state == True :\n",
    "                # 세트 수 만큼 반복\n",
    "            for set_count in range(int(input_sets)):\n",
    "                print(f\"\\n{set_count + 1}세트를 시작합니다.\\n\")\n",
    "\n",
    "                # 카운트 초기화\n",
    "                count = 0\n",
    "                count_s = -1\n",
    "                detected = False\n",
    "                less_count = False\n",
    "                more_count = False\n",
    "\n",
    "                # VideoWriter 설정\n",
    "                file_path = f'../실전 deep/exercise_videos/{exercise_type}_record_{set_count+1}.mp4'\n",
    "                fps = 25.40\n",
    "                fourcc = cv2.VideoWriter_fourcc(*'DIVX')  # 인코딩 포맷 문자\n",
    "                width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "                height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "                size = (width, height)  # 프레임 크기\n",
    "                out = cv2.VideoWriter(file_path, fourcc, fps, size)  # VideoWriter 객체 생성\n",
    "\n",
    "\n",
    "                # 운동 감지 및 동영상 녹화\n",
    "                start_time = time.time()\n",
    "                last_count_time = start_time\n",
    "\n",
    "                while cap.isOpened():\n",
    "                    ret, frame = cap.read()\n",
    "                    if not ret:\n",
    "                        break\n",
    "\n",
    "                    # RGB로 변환\n",
    "                    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "                    # 미디어파이프를 사용하여 관절 포인트 감지\n",
    "                    results = pose.process(rgb_frame)\n",
    "\n",
    "                    # 현재 프레임의 시간 계산\n",
    "                    current_time = time.time() - start_time\n",
    "\n",
    "                    if results.pose_landmarks:\n",
    "\n",
    "\n",
    "                        # 앵글 계산\n",
    "                        right_shoulder = (int(results.pose_landmarks.landmark[JOINTS[\"right_shoulder\"]].x * frame.shape[1]),\n",
    "                                          int(results.pose_landmarks.landmark[JOINTS[\"right_shoulder\"]].y * frame.shape[0]))\n",
    "                        right_elbow = (int(results.pose_landmarks.landmark[JOINTS[\"right_elbow\"]].x * frame.shape[1]),\n",
    "                                       int(results.pose_landmarks.landmark[JOINTS[\"right_elbow\"]].y * frame.shape[0]))\n",
    "                        right_wrist = (int(results.pose_landmarks.landmark[JOINTS[\"right_wrist\"]].x * frame.shape[1]),\n",
    "                                       int(results.pose_landmarks.landmark[JOINTS[\"right_wrist\"]].y * frame.shape[0]))\n",
    "\n",
    "                        left_shoulder = (int(results.pose_landmarks.landmark[JOINTS[\"left_shoulder\"]].x * frame.shape[1]),\n",
    "                                         int(results.pose_landmarks.landmark[JOINTS[\"left_shoulder\"]].y * frame.shape[0]))\n",
    "                        left_elbow = (int(results.pose_landmarks.landmark[JOINTS[\"left_elbow\"]].x * frame.shape[1]),\n",
    "                                      int(results.pose_landmarks.landmark[JOINTS[\"left_elbow\"]].y * frame.shape[0]))\n",
    "                        left_wrist = (int(results.pose_landmarks.landmark[JOINTS[\"left_wrist\"]].x * frame.shape[1]),\n",
    "                                      int(results.pose_landmarks.landmark[JOINTS[\"left_wrist\"]].y * frame.shape[0]))\n",
    "\n",
    "                        right_hip = (int(results.pose_landmarks.landmark[JOINTS[\"right_hip\"]].x * frame.shape[1]),\n",
    "                                     int(results.pose_landmarks.landmark[JOINTS[\"right_hip\"]].y * frame.shape[0]))\n",
    "                        right_knee = (int(results.pose_landmarks.landmark[JOINTS[\"right_knee\"]].x * frame.shape[1]),\n",
    "                                       int(results.pose_landmarks.landmark[JOINTS[\"right_knee\"]].y * frame.shape[0]))\n",
    "                        right_ankle = (int(results.pose_landmarks.landmark[JOINTS[\"right_ankle\"]].x * frame.shape[1]),\n",
    "                                      int(results.pose_landmarks.landmark[JOINTS[\"right_ankle\"]].y * frame.shape[0]))\n",
    "\n",
    "                        left_hip = (int(results.pose_landmarks.landmark[JOINTS[\"left_hip\"]].x * frame.shape[1]),\n",
    "                                    int(results.pose_landmarks.landmark[JOINTS[\"left_hip\"]].y * frame.shape[0]))\n",
    "                        left_knee = (int(results.pose_landmarks.landmark[JOINTS[\"left_knee\"]].x * frame.shape[1]),\n",
    "                                     int(results.pose_landmarks.landmark[JOINTS[\"left_knee\"]].y * frame.shape[0]))\n",
    "                        left_ankle = (int(results.pose_landmarks.landmark[JOINTS[\"left_ankle\"]].x * frame.shape[1]),\n",
    "                                       int(results.pose_landmarks.landmark[JOINTS[\"left_ankle\"]].y * frame.shape[0]))\n",
    "\n",
    "                        # 각 앵글 계산\n",
    "                        right_shoulder_elbow_wrist_angle = calculate_angle(right_shoulder, right_elbow, right_wrist)\n",
    "                        left_shoulder_elbow_wrist_angle = calculate_angle(left_shoulder, left_elbow, left_wrist)\n",
    "                        right_hip_knee_ankle_angle = calculate_angle(right_hip, right_knee, right_ankle)\n",
    "                        left_hip_knee_ankle_angle = calculate_angle(left_hip, left_knee, left_ankle)\n",
    "                        right_knee_hip_shoulder_angle = calculate_angle(right_knee, right_hip, right_shoulder)\n",
    "                        left_knee_hip_shoulder_angle = calculate_angle(left_knee, left_hip, left_shoulder)\n",
    "                        right_ankle_hip_shoulder_angle = calculate_angle(right_ankle, right_hip, right_shoulder)\n",
    "                        left_ankle_hip_shoulder_angle = calculate_angle(left_ankle, left_hip, left_shoulder)\n",
    "\n",
    "                        # 결과를 리스트에 기록\n",
    "                        right_shoulder_elbow_wrist_angles.append(right_shoulder_elbow_wrist_angle)\n",
    "                        left_shoulder_elbow_wrist_angles.append(left_shoulder_elbow_wrist_angle)\n",
    "                        right_hip_knee_ankle_angles.append(right_hip_knee_ankle_angle)\n",
    "                        left_hip_knee_ankle_angles.append(left_hip_knee_ankle_angle)\n",
    "                        right_knee_hip_shoulder_angles.append(right_knee_hip_shoulder_angle)\n",
    "                        left_knee_hip_shoulder_angles.append(left_knee_hip_shoulder_angle)\n",
    "                        right_ankle_hip_shoulder_angles.append(right_ankle_hip_shoulder_angle)\n",
    "                        left_ankle_hip_shoulder_angles.append(left_ankle_hip_shoulder_angle)\n",
    "\n",
    "                        # 화면에 카운트 표시\n",
    "                        cv2.putText(frame, f\"Count: {count}\", count_position, font, 1.2, (0, 0, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "                        # 스쿼트 감지\n",
    "                        if exercise_type.lower() == 'squat':\n",
    "                #             준비자세\n",
    "                            right_squat = 140 <= right_hip_knee_ankle_angle <= 200\n",
    "                            left_squat = 140 <= left_hip_knee_ankle_angle <= 200\n",
    "\n",
    "                #         준비자세가 되면\n",
    "                            if right_squat and left_squat :\n",
    "                                if not detected :\n",
    "                                    count_s += 1\n",
    "                                        # detected 완벽한 자세 감지\n",
    "                                    detected = True\n",
    "                                    if count_s > 0:\n",
    "                                        print(f\"운동 횟수: {count_s}회\")\n",
    "                                        text_to_speech(f\"{count_s}회\", lang='ko', filename='outSound.mp3')\n",
    "                                        count = count_s\n",
    "                                if less_count :\n",
    "                                    print('덜 앉음')\n",
    "                                    less_count = False\n",
    "                                    text_to_speech(\"덜 앉았습니다.\", lang='ko', filename='outSound.mp3')\n",
    "\n",
    "                                if more_count :\n",
    "                                    print('깊게 앉음')\n",
    "                                    more_count = False\n",
    "                                    text_to_speech(\"깊게 앉았습니다.\", lang='ko', filename='outSound.mp3')\n",
    "\n",
    "\n",
    "                            #  덜앉음\n",
    "                            if (220 <= right_hip_knee_ankle_angle < 250 and 220 <= left_hip_knee_ankle_angle < 250) or \\\n",
    "                                (100 <= right_hip_knee_ankle_angle < 140 and 100 <= left_hip_knee_ankle_angle < 140) and not (\n",
    "                                right_squat and left_squat) :\n",
    "                                if detected and not more_count:\n",
    "                                    less_count = True\n",
    "\n",
    "                            # 앉았을 때\n",
    "                            if (80 <= right_hip_knee_ankle_angle <= 100 or 80 <= left_hip_knee_ankle_angle <= 100) or \\\n",
    "                                    (250 <= right_hip_knee_ankle_angle <= 270 or 250 <= left_hip_knee_ankle_angle <= 270) and not (right_squat and left_squat):\n",
    "                                    if not more_count:\n",
    "                                        detected = False\n",
    "                                        less_count = False\n",
    "\n",
    "                               # 깊게 앉음\n",
    "                            if (0 <= right_knee_hip_shoulder_angle <= 50 or 0 <= left_knee_hip_shoulder_angle <= 50) or \\\n",
    "                                        (300 <= right_knee_hip_shoulder_angle <= 350 or 300 <= left_knee_hip_shoulder_angle <= 350):\n",
    "                                more_count = True\n",
    "                                detected = True\n",
    "                                less_count = False\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                        # 푸쉬업 감지\n",
    "                        if exercise_type.lower() == 'pushup':\n",
    "                            right_pushup = 150 <= right_shoulder_elbow_wrist_angle <= 210\n",
    "                            left_pushup = 150 <= left_shoulder_elbow_wrist_angle <= 210\n",
    "                            pushup_hip = 160 <= right_ankle_hip_shoulder_angle <= 200 and 160 <= left_ankle_hip_shoulder_angle <= 200\n",
    "\n",
    "                            if right_pushup and left_pushup and pushup_hip:\n",
    "                                if not detected :\n",
    "                                    count_s += 1\n",
    "                                    detected = True\n",
    "                                    if count_s > 0:\n",
    "                                        print(f\"운동 횟수: {count_s}회\")\n",
    "                                        text_to_speech(f\"{count_s}회\", lang='ko', filename='outSound.mp3')\n",
    "                                        count = count_s\n",
    "                                if less_count :\n",
    "                                    print('팔 덜 내림')\n",
    "                                    less_count = False\n",
    "                                    text_to_speech(\"더 내려가세요\", lang='ko', filename='outSound.mp3')\n",
    "                                if more_count :\n",
    "                                    more_count = False\n",
    "\n",
    "                            # 팔 덜굽힐 때\n",
    "                            if (100 <= right_shoulder_elbow_wrist_angle <= 140 and 100 <= left_shoulder_elbow_wrist_angle <= 140) or \\\n",
    "                                (220 <= right_shoulder_elbow_wrist_angle <= 260 and 220 <= left_shoulder_elbow_wrist_angle <= 260 ) and not \\\n",
    "                                (right_pushup and left_pushup) :\n",
    "                                if detected :\n",
    "                                    less_count = True\n",
    "\n",
    "                            # 팔이 벌어지고 다시 펴졌을 때\n",
    "                            if (40 <= right_shoulder_elbow_wrist_angle <= 80 or 40 <= left_shoulder_elbow_wrist_angle <= 80) or (270<= right_shoulder_elbow_wrist_angle <= 330 or 270 <= left_shoulder_elbow_wrist_angle <= 330) and not (right_pushup or left_pushup) :\n",
    "                                if not more_count :\n",
    "                                    detected = False\n",
    "                                    less_count = False\n",
    "\n",
    "                            # 엉덩이 높이 벗어날 때\n",
    "                            if not pushup_hip :\n",
    "                                if not more_count :\n",
    "                                    detected = True\n",
    "                                    more_count = True\n",
    "                                    print('엉덩이 벗어남')\n",
    "                                    text_to_speech(\"엉덩이가 벗어났습니다.\", lang='ko', filename='outSound.mp3')\n",
    "\n",
    "                        # 풀업 감지\n",
    "                        if exercise_type.lower() == 'pullup':\n",
    "                            # 올라갈 때\n",
    "                            pullup = (0 <= right_shoulder_elbow_wrist_angle <= 50 or 300 <= right_shoulder_elbow_wrist_angle <= 350) and \\\n",
    "                                        (0 <= left_shoulder_elbow_wrist_angle <= 50 or 300 <= left_shoulder_elbow_wrist_angle <= 350)\n",
    "\n",
    "                            if pullup :\n",
    "                                if not detected :\n",
    "                                    count += 1\n",
    "                                    detected = True\n",
    "                                    print(f\"운동 횟수: {count}회\")\n",
    "                                    text_to_speech(f\"{count}회\", lang='ko', filename='outSound.mp3')\n",
    "                                    pygame.init()\n",
    "                                    pygame.mixer.init()\n",
    "                                    more_count = False\n",
    "                                if less_count :\n",
    "                                    print('덜 내려감')\n",
    "                                    less_count = False\n",
    "                                    text_to_speech(\"더 내려가세요.\", lang='ko', filename='outSound.mp3')\n",
    "\n",
    "\n",
    "                            if (250 <= right_shoulder_elbow_wrist_angle <= 300 or 50 <= right_shoulder_elbow_wrist_angle <= 100) and \\\n",
    "                                (250 <= left_shoulder_elbow_wrist_angle <= 300 or 50 <= left_shoulder_elbow_wrist_angle <= 100) :\n",
    "                                # 덜 올라갈 때\n",
    "                                if not detected : \n",
    "                                    more_count = True\n",
    "                                # 덜 내려갈 때\n",
    "                                if detected : \n",
    "                                    less_count = True\n",
    "\n",
    "                            # 팔 다 폈을 때\n",
    "                            if (200 <= right_shoulder_elbow_wrist_angle <= 250 or 100 <= right_shoulder_elbow_wrist_angle <= 150) and \\\n",
    "                                (200 <= left_shoulder_elbow_wrist_angle <= 250 or 100 <= left_shoulder_elbow_wrist_angle <= 150) :\n",
    "                                detected = False\n",
    "                                less_count = False\n",
    "                                if more_count :\n",
    "                                    print('덜 올라감')\n",
    "                                    text_to_speech(\"더 올라가세요.\", lang='ko', filename='outSound.mp3')\n",
    "                                    more_count = False\n",
    "\n",
    "\n",
    "\n",
    "                        # 관절을 선으로 이어서 그리기\n",
    "                        mp_drawing.draw_landmarks(frame, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "\n",
    "                    # 시작 5초 후부터 운동 감지 및 녹화 시작\n",
    "                    if current_time > 5:\n",
    "                        # 프레임을 녹화 동영상에 저장\n",
    "                        out.write(frame)\n",
    "\n",
    "                         # 운동 횟수가 +1 될 때마다 시간 갱신\n",
    "                        if count > 0 and count % 2 == 0:  # 예시: count가 짝수일 때마다 갱신\n",
    "                            last_count_time = time.time()\n",
    "\n",
    "                        if count >= input_count :\n",
    "                            print(f\"운동 횟수 {input_count} 달성 또는 시간 초과! 동영상 녹화를 중지합니다.\")\n",
    "                            break\n",
    "\n",
    "                        # 10초 동안 운동 횟수가 갱신되지 않으면 녹화 중지\n",
    "                        if time.time() - last_count_time > 10:\n",
    "                            print(\"운동 횟수 10초 동안 갱신 없음. 동영상 녹화를 중지합니다.\")\n",
    "                            break\n",
    "\n",
    "                    # 화면에 출력\n",
    "                    cv2.imshow('Pose Detection', frame)\n",
    "\n",
    "\n",
    "                    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                        break\n",
    "\n",
    "                out.release()\n",
    "\n",
    "                cv2.destroyAllWindows()\n",
    "\n",
    "                # 휴식 시간만큼 대기\n",
    "                if set_count < int(input_sets) - 1:\n",
    "                    print(f\"\\n휴식 시간 {input_rest}초를 기다립니다...\\n\")\n",
    "                    last_count_time = time.time()\n",
    "                    if time.time() - last_count_time < int(input_rest) :\n",
    "                        print('Listening !!! ')\n",
    "                        try:\n",
    "                            while time.time() - last_count_time < int(input_rest):\n",
    "                                pcm = recorder.read()\n",
    "                                result = porcupine.process(pcm)\n",
    "\n",
    "\n",
    "                                if wav_file is not None:\n",
    "                                    wav_file.writeframes(struct.pack(\"h\" * len(pcm), *pcm))\n",
    "\n",
    "                                if result >= 0:\n",
    "                                    detected_keyword = keywords[result]\n",
    "                                    text_to_speech(\"알통이 등장\", lang='ko', filename='outSound.mp3')\n",
    "                                    # play_audio('outSound.mp3')\n",
    "\n",
    "\n",
    "                                    while time.time() - last_count_time < int(input_rest):\n",
    "                                        print('[%s] Detected %s' % (str(datetime.now()), detected_keyword))\n",
    "\n",
    "                                        # 음성 녹음\n",
    "                                        record_audio(file_path, duration)\n",
    "\n",
    "                                        # 음성을 텍스트로 변환\n",
    "                                        transcribed_text = transcribe_audio(file_path)\n",
    "\n",
    "                                        # 변환된 텍스트를 출력\n",
    "                                        print(\"Transcribed Text:\", transcribed_text)\n",
    "\n",
    "                                        # embeding_query 함수를 호출하여 query_result를 얻어오기\n",
    "                                        query_result = embeding_query(transcribed_text[0])\n",
    "\n",
    "                                        # 정확도 (score)가 0.85 이상인 경우\n",
    "                                        if query_result['matches'][0]['score'] >= 0.85:\n",
    "                                            # 해당 id에 따라 다른 동작 수행\n",
    "                                            if query_result['matches'][0]['id'] == 'next':\n",
    "                                                text_to_speech(\"다음 운동은 스쿼트 입니다!\", lang='ko', filename='outSound.mp3')\n",
    "\n",
    "                                            elif query_result['matches'][0]['id'] == 'record':\n",
    "                                                text_to_speech(\"오늘 운동한 시간은 총 30분 입니다!\", lang='ko', filename='outSound.mp3')\n",
    "\n",
    "                                            elif query_result['matches'][0]['id'] == 'calorie':\n",
    "                                                text_to_speech(\"오늘 소비한 칼로리는 총 100칼로리 입니다!\", lang='ko', filename='outSound.mp3')\n",
    "\n",
    "\n",
    "                                        elif query_result['matches'][0]['score'] < 0.85 and not transcribed_text[0] == 'No speech detected':\n",
    "                                            # openai 답변 받아오기\n",
    "                                            chat_model = ChatOpenAI(openai_api_key=OPENAI_API_KEY)\n",
    "                                            response_stream = chat_model.predict(transcribed_text[0], stream=True)\n",
    "                                            text_to_speech(response_stream, lang='ko', filename='outSound.mp3')\n",
    "\n",
    "\n",
    "                        except KeyboardInterrupt:\n",
    "                            print('Stopping !!!')\n",
    "                            recorder.delete()\n",
    "                            porcupine.delete()\n",
    "                            if wav_file is not None:\n",
    "                                wav_file.close()\n",
    "        \n",
    "                        cap.release()\n",
    "                        cap = cv2.VideoCapture('푸쉬업.mp4')\n",
    "\n",
    "                cv2.destroyAllWindows()\n",
    "            user_state = False\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    pygame.init()\n",
    "    pygame.mixer.init()\n",
    "    main()\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce13b9d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pygame in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (2.5.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install pygame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d9b9ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
